# AI Assistant Prompts

This directory contains reusable prompt templates for AI assistants (Claude, Copilot, ChatGPT, etc.) working with the Market Data Collector codebase.

## Available Prompts

| Prompt | Description | Use When |
|--------|-------------|----------|
| [project-context.prompt.yml](project-context.prompt.yml) | Project overview and coding conventions | Starting any task, need project context |
| [code-review.prompt.yml](code-review.prompt.yml) | Comprehensive code review guidelines | Reviewing PRs or code changes |
| [add-data-provider.prompt.yml](add-data-provider.prompt.yml) | Guide for adding new data providers | Implementing new market data integrations |
| [provider-implementation-guide.prompt.yml](provider-implementation-guide.prompt.yml) | Detailed IMarketDataClient patterns | Implementing streaming providers |
| [write-unit-tests.prompt.yml](write-unit-tests.prompt.yml) | Unit test generation guidelines | Writing tests for components |
| [explain-architecture.prompt.yml](explain-architecture.prompt.yml) | Architecture explanation guide | Understanding system design |
| [troubleshoot-issue.prompt.yml](troubleshoot-issue.prompt.yml) | Issue diagnosis and resolution | Debugging problems |
| [optimize-performance.prompt.yml](optimize-performance.prompt.yml) | Performance optimization guidance | Improving hot paths |
| [configure-deployment.prompt.yml](configure-deployment.prompt.yml) | Deployment configuration help | Setting up environments |
| [add-export-format.prompt.yml](add-export-format.prompt.yml) | Export format implementation | Adding new export types |
| [wpf-debug-improve.prompt.yml](wpf-debug-improve.prompt.yml) | WPF debugging and improvement guide | Fixing or completing WPF UI work |

## How to Use

### With GitHub Copilot Chat

Reference a prompt in your chat:

```
@workspace /explain Use the explain-architecture prompt to explain the event pipeline
```

### With Claude Code

The prompts work as context for Claude Code sessions. Reference the project context:

```
Read .github/prompts/project-context.prompt.yml and use it as context for this task: [your task]
```

### Manual Use

Copy the system message content from any prompt file and use it as context for your AI assistant.

## Prompt Structure

Each prompt follows a standard structure:

```yaml
name: Prompt Name
description: What this prompt helps with
# Model-agnostic prompt - works with any capable LLM
messages:
  - role: system
    content: |
      Context and instructions for the AI...
  - role: user
    content: |
      Template with {{placeholders}} for user input...
```

## Quick Reference

### Development Tasks

- **New provider**: `add-data-provider.prompt.yml` + `provider-implementation-guide.prompt.yml`
- **New export format**: `add-export-format.prompt.yml`
- **Write tests**: `write-unit-tests.prompt.yml`
- **Code review**: `code-review.prompt.yml`

### Understanding & Troubleshooting

- **Architecture questions**: `explain-architecture.prompt.yml`
- **Debug issues**: `troubleshoot-issue.prompt.yml`
- **Performance problems**: `optimize-performance.prompt.yml`

### DevOps

- **Deployment setup**: `configure-deployment.prompt.yml`

## Auto-Generated Prompts

Some prompts are automatically generated by the **Prompt Generation** workflow (`.github/workflows/prompt-generation.yml`). These prompts are created from CI/CD workflow run results to help address specific failures.

### How It Works

1. A monitored workflow (test-matrix, code-quality, security, benchmarks, docker) completes with a failure
2. The prompt generation workflow triggers automatically (or can be triggered manually)
3. It fetches the failed run's logs, annotations, and job results
4. It classifies failures into categories (build, test, code-quality, security, docker, performance)
5. It generates targeted `.prompt.yml` files with the failure context baked in
6. A PR is created with the generated prompts for review

### Auto-Generated Prompt Types

| Prompt | Generated When |
|--------|---------------|
| `fix-build-errors.prompt.yml` | Build failures (CS/NU/NETSDK errors) |
| `fix-test-failures.prompt.yml` | Test failures (failed assertions, test runs) |
| `fix-code-quality.prompt.yml` | Code quality warnings (CA/SA/IDE rules) |
| `fix-security-issues.prompt.yml` | Security vulnerabilities (CVEs, CodeQL) |
| `fix-docker-issues.prompt.yml` | Docker build/deployment failures |
| `fix-performance-regression.prompt.yml` | Performance benchmark regressions |
| `workflow-results-{name}.prompt.yml` | Summary prompt for a specific workflow |

### Manual Trigger

Run the workflow manually from the Actions tab:

```
Workflow: Prompt Generation
Inputs:
  - workflow: test-matrix.yml    # Which workflow to analyze
  - run_id: 0                    # 0 = most recent failed run
  - dry_run: false               # Preview without committing
  - create_pr: true              # Create PR with generated prompts
```

### CI/CD Integration

The script can also be run locally:

```bash
python3 build/scripts/docs/generate-prompts.py \
  --workflow test-matrix.yml \
  --output .github/prompts/ \
  --summary
```

## Adding New Prompts

### Manual Prompts

1. Create a new `.prompt.yml` file in this directory
2. Follow the existing structure (name, description, messages)
3. Include relevant project context in the system message
4. Add placeholders (`{{variable}}`) for user-provided values
5. Update this README with the new prompt

### Auto-Generated Prompts

Auto-generated prompts are created via the Prompt Generation workflow. To add support for new failure categories, edit `build/scripts/docs/generate-prompts.py` and add entries to the `FAILURE_CATEGORIES` dict.

## Related Resources

- [CLAUDE.md](../../CLAUDE.md) - Main project instructions for AI assistants
- [copilot-instructions.md](../../docs/ai/copilot/instructions.md) - GitHub Copilot configuration
- [agents/](../agents/) - AI agent configurations

---

**Last Updated**: 2026-02-10
