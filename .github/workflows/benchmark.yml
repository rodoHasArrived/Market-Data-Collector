name: Benchmark Performance

on:
  push:
    branches: [ "main" ]
    paths:
      - 'src/**'
      - 'benchmarks/**'
      - '.github/workflows/benchmark.yml'
  pull_request:
    branches: [ "main" ]
    paths:
      - 'src/**'
      - 'benchmarks/**'
  workflow_dispatch:
    inputs:
      filter:
        description: 'Benchmark filter pattern (e.g., *Parser*, *Collector*)'
        required: false
        default: '*'
      compare_baseline:
        description: 'Compare with baseline'
        required: false
        default: 'true'
        type: boolean

permissions:
  contents: read
  issues: write
  pull-requests: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  DOTNET_VERSION: '9.0.x'
  DOTNET_NOLOGO: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true

# Cancel in-progress runs for the same workflow and branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  benchmark:
    name: Run Benchmarks
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: '9.0.x'

    - name: Cache NuGet packages
      uses: actions/cache@v4
      with:
        path: ~/.nuget/packages
        key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj', '**/*.fsproj') }}
        restore-keys: |
          ${{ runner.os }}-nuget-

    - name: Restore dependencies
      run: dotnet restore benchmarks/MarketDataCollector.Benchmarks/MarketDataCollector.Benchmarks.csproj /p:EnableWindowsTargeting=true

    - name: Build benchmarks
      run: dotnet build benchmarks/MarketDataCollector.Benchmarks/MarketDataCollector.Benchmarks.csproj -c Release --no-restore /p:EnableWindowsTargeting=true

    - name: Run benchmarks
      run: dotnet run --project benchmarks/MarketDataCollector.Benchmarks/MarketDataCollector.Benchmarks.csproj -c Release --no-build -- --filter '*' --exporters json --exporters html --exporters markdown

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: benchmark-results
        path: BenchmarkDotNet.Artifacts/
        retention-days: 30

    - name: Store benchmark results
      if: github.event_name == 'push' && github.ref == 'refs/heads/main'
      uses: benchmark-action/github-action-benchmark@v1
      with:
        tool: 'benchmarkdotnet'
        output-file-path: BenchmarkDotNet.Artifacts/results/combined-benchmarks.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        alert-threshold: '150%'
        comment-on-alert: true
        fail-on-alert: false

    - name: Comment PR with benchmark results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');
          const path = require('path');

          let comment = '## ðŸ“Š Benchmark Results\n\n';

          // Try to read markdown summary if available
          const markdownPath = 'BenchmarkDotNet.Artifacts/results/MarketDataCollector.Benchmarks-report-github.md';
          if (fs.existsSync(markdownPath)) {
            const markdownContent = fs.readFileSync(markdownPath, 'utf8');
            comment += markdownContent + '\n\n';
          } else {
            comment += 'Benchmark suite completed successfully.\n\n';
          }

          comment += 'ðŸ“ Full results have been uploaded as artifacts and can be downloaded from the Actions tab.\n';
          comment += '\n**Artifact name:** `benchmark-results`\n';
          comment += '\n---\n';
          comment += '*Performance benchmarks are run on every PR to ensure no regressions.*\n';

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Restore dependencies
        run: dotnet restore /p:EnableWindowsTargeting=true

      - name: Build benchmark project
        run: dotnet build benchmarks/MarketDataCollector.Benchmarks -c Release --no-restore

      - name: Run benchmarks
        run: |
          mkdir -p benchmark-results

          dotnet run \
            --project benchmarks/MarketDataCollector.Benchmarks \
            -c Release \
            --no-build \
            -- \
            --exporters json markdown html \
            --artifacts benchmark-results \
            --filter '*' \
            --job short

      - name: Generate benchmark summary
        run: |
          echo "## Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Date:** $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Find and include markdown results
          if [ -f "benchmark-results/results/MarketDataCollector.Benchmarks-report.md" ]; then
            cat benchmark-results/results/MarketDataCollector.Benchmarks-report.md >> $GITHUB_STEP_SUMMARY
          else
            # Try to find any markdown report
            REPORT=$(find benchmark-results -name "*.md" -type f | head -1)
            if [ -n "$REPORT" ]; then
              cat "$REPORT" >> $GITHUB_STEP_SUMMARY
            else
              echo "No benchmark report found" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          cache: true

      - name: Restore dependencies
        run: dotnet restore benchmarks/MarketDataCollector.Benchmarks/MarketDataCollector.Benchmarks.csproj /p:EnableWindowsTargeting=true

      - name: Build benchmarks
        run: |
          dotnet build benchmarks/MarketDataCollector.Benchmarks/MarketDataCollector.Benchmarks.csproj \
            -c Release \
            --no-restore \
            /p:EnableWindowsTargeting=true

      - name: Download baseline results
        if: github.event_name == 'pull_request' || (github.event_name == 'workflow_dispatch' && github.event.inputs.compare_baseline == 'true')
        uses: dawidd6/action-download-artifact@v3
        with:
          name: benchmark-baseline
          workflow: benchmark.yml
          branch: main
          path: ./baseline
        continue-on-error: true

      - name: Run benchmarks
        run: |
          filter="${{ github.event.inputs.filter || '*' }}"
          dotnet run --project benchmarks/MarketDataCollector.Benchmarks/MarketDataCollector.Benchmarks.csproj \
            -c Release \
            --no-build \
            -- \
            --filter "$filter" \
            --exporters json html markdown github \
            --memory \
            --disasm \
            --artifacts ./BenchmarkDotNet.Artifacts

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.sha }}
          path: benchmark-results/
          retention-days: 90

      - name: Store benchmark result for tracking
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        uses: actions/cache/save@v4
        with:
          path: benchmark-results/
          key: benchmark-${{ github.sha }}

  compare-benchmarks:
    name: Compare Against Baseline
    runs-on: ubuntu-latest
    needs: benchmark
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Download current benchmark results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results-${{ github.sha }}
          path: current-results

      - name: Try to restore baseline benchmarks
        id: restore-baseline
        uses: actions/cache/restore@v4
        with:
          path: baseline-results/
          key: benchmark-${{ github.event.pull_request.base.sha }}
          restore-keys: |
            benchmark-

      - name: Compare benchmarks
        if: steps.restore-baseline.outputs.cache-hit == 'true'
        run: |
          echo "## Benchmark Comparison" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Comparing against baseline: ${{ github.event.pull_request.base.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Simple comparison script
          if [ -f "baseline-results/results/MarketDataCollector.Benchmarks-report.json" ] && \
             [ -f "current-results/results/MarketDataCollector.Benchmarks-report.json" ]; then
            echo "### Performance Changes" >> $GITHUB_STEP_SUMMARY
            echo "Benchmark comparison is available in the artifacts." >> $GITHUB_STEP_SUMMARY
          else
            echo "Baseline results not available for comparison." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Comment on PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            let report = '## ðŸ“Š Benchmark Results\n\n';
            report += `**Commit:** \`${{ github.sha }}\`\n\n`;

            // Try to read the markdown report
            try {
              const files = fs.readdirSync('current-results/results');
              const mdFile = files.find(f => f.endsWith('-report.md'));
              if (mdFile) {
                const content = fs.readFileSync(`current-results/results/${mdFile}`, 'utf8');
                // Truncate if too long
                report += content.length > 60000 ? content.substring(0, 60000) + '\n\n*Report truncated*' : content;
              } else {
                report += 'No detailed benchmark report available.';
              }
            } catch (e) {
              report += `Could not read benchmark results: ${e.message}`;
            }

            // Find existing comment to update
          name: benchmark-results
          path: BenchmarkDotNet.Artifacts/
          retention-days: 30

      - name: Save baseline (main branch only)
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-baseline
          path: BenchmarkDotNet.Artifacts/results/
          retention-days: 90

      - name: Compare with baseline
        if: github.event_name == 'pull_request'
        id: compare
        run: |
          echo "## Benchmark Comparison" >> comparison.md
          echo "" >> comparison.md

          if [ -d "./baseline" ] && [ "$(ls -A ./baseline 2>/dev/null)" ]; then
            echo "Comparing with baseline from main branch..." >> comparison.md
            echo "" >> comparison.md

            # Find JSON result files
            current_results=$(find ./BenchmarkDotNet.Artifacts/results -name "*.json" 2>/dev/null | head -1)
            baseline_results=$(find ./baseline -name "*.json" 2>/dev/null | head -1)

            if [ -n "$current_results" ] && [ -n "$baseline_results" ]; then
              echo "ðŸ“Š Performance comparison available in artifacts" >> comparison.md

              # Extract and compare key metrics (simplified comparison)
              echo "" >> comparison.md
              echo "### Current Run Summary" >> comparison.md
              echo '```' >> comparison.md
              if [ -f "./BenchmarkDotNet.Artifacts/results/MarketDataCollector.Benchmarks-report-github.md" ]; then
                cat "./BenchmarkDotNet.Artifacts/results/MarketDataCollector.Benchmarks-report-github.md" | head -50 >> comparison.md
              else
                echo "Detailed results in artifacts" >> comparison.md
              fi
              echo '```' >> comparison.md
            else
              echo "âš ï¸ Could not find result files for comparison" >> comparison.md
            fi
          else
            echo "â„¹ï¸ No baseline available for comparison (first run or baseline expired)" >> comparison.md
          fi

          echo "" >> comparison.md
          echo "ðŸ“ **Artifacts:** Full benchmark results, memory analysis, and disassembly available in workflow artifacts" >> comparison.md

          echo "comparison_available=true" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Comment PR with benchmark results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');

            let comment = '## ðŸ“Š Benchmark Results\n\n';

            // Read comparison file if available
            try {
              const comparison = fs.readFileSync('comparison.md', 'utf8');
              comment += comparison + '\n\n';
            } catch (e) {
              comment += 'Benchmark suite completed successfully.\n\n';
            }

            // Try to read the GitHub markdown report
            try {
              const reportPath = './BenchmarkDotNet.Artifacts/results/MarketDataCollector.Benchmarks-report-github.md';
              if (fs.existsSync(reportPath)) {
                const report = fs.readFileSync(reportPath, 'utf8');
                comment += '### Results\n\n';
                comment += report.substring(0, 3000); // Limit size
                if (report.length > 3000) {
                  comment += '\n\n... (truncated, see artifacts for full report)';
                }
              }
            } catch (e) {
              // Ignore
            }

            comment += '\n\n---\n';
            comment += '**Artifact name:** `benchmark-results`\n';
            comment += '**Memory profiling:** Enabled\n';
            comment += '**Disassembly:** Available in artifacts\n';

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' && c.body.includes('ðŸ“Š Benchmark Results')
            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' && comment.body.includes('Benchmark Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: report
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: report
              });
            }

  memory-profile:
    name: Memory Profiling
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }

  memory-profiling:
    name: Memory Profiling
    runs-on: ubuntu-latest
    needs: benchmark

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Restore dependencies
        run: dotnet restore /p:EnableWindowsTargeting=true

      - name: Build with memory diagnostics
        run: |
          dotnet build benchmarks/MarketDataCollector.Benchmarks \
            -c Release \
            /p:EnableWindowsTargeting=true \
            --no-restore

      - name: Run memory benchmarks
        run: |
          mkdir -p memory-results

          dotnet run \
            --project benchmarks/MarketDataCollector.Benchmarks \
            -c Release \
            --no-build \
            -- \
            --filter '*Memory*' \
            --memory \
            --exporters json \
            --artifacts memory-results \
            --job dry || echo "No memory-specific benchmarks found"

      - name: Generate memory report
        run: |
          echo "## Memory Profile" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -d "memory-results/results" ]; then
            for file in memory-results/results/*.json; do
              if [ -f "$file" ]; then
                echo "Memory benchmark results available in artifacts" >> $GITHUB_STEP_SUMMARY
          cache: true

      - name: Restore dependencies
        run: dotnet restore benchmarks/MarketDataCollector.Benchmarks/MarketDataCollector.Benchmarks.csproj /p:EnableWindowsTargeting=true

      - name: Build benchmarks
        run: |
          dotnet build benchmarks/MarketDataCollector.Benchmarks/MarketDataCollector.Benchmarks.csproj \
            -c Release \
            --no-restore \
            /p:EnableWindowsTargeting=true

      - name: Run memory-focused benchmarks
        run: |
          dotnet run --project benchmarks/MarketDataCollector.Benchmarks/MarketDataCollector.Benchmarks.csproj \
            -c Release \
            --no-build \
            -- \
            --filter '*' \
            --memory \
            --allCategories \
            --exporters json \
            --artifacts ./MemoryProfile
        continue-on-error: true

      - name: Analyze memory results
        run: |
          echo "## Memory Profile Analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Find and display memory-related metrics from results
          if [ -d "./MemoryProfile/results" ]; then
            echo "### Memory Allocation Summary" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Extract key metrics from JSON if available
            for jsonfile in ./MemoryProfile/results/*.json; do
              if [ -f "$jsonfile" ]; then
                echo "ðŸ“Š Memory profiling results available in artifacts" >> $GITHUB_STEP_SUMMARY
                break
              fi
            done
          else
            echo "No memory benchmarks executed" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload memory results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: memory-profile-${{ github.sha }}
          path: memory-results/
          retention-days: 30
            echo "âš ï¸ No memory profiling results found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload memory profile
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: memory-profile
          path: ./MemoryProfile/
          retention-days: 14

  benchmark-summary:
    name: Benchmark Summary
    runs-on: ubuntu-latest
    needs: [benchmark, memory-profiling]
    if: always()

    steps:
      - name: Generate benchmark summary
        run: |
          echo "# Benchmark Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Date:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Job Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Benchmarks | ${{ needs.benchmark.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Memory Profiling | ${{ needs.memory-profiling.result == 'success' && 'âœ… Passed' || 'âš ï¸ Check logs' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **benchmark-results**: Full benchmark results with HTML, JSON, and Markdown reports" >> $GITHUB_STEP_SUMMARY
          echo "- **benchmark-baseline**: Baseline for comparison (main branch only)" >> $GITHUB_STEP_SUMMARY
          echo "- **memory-profile**: Detailed memory allocation analysis" >> $GITHUB_STEP_SUMMARY
