# Code Quality Workflow
# Runs code formatting checks, static analysis, and documentation validation
# Consolidated into single job to reduce restore/build cycles

name: Code Quality

on:
  push:
    branches: [ "main" ]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'benchmarks/**'
      - '*.props'
      - '*.targets'
      - '**/*.csproj'
      - '**/*.fsproj'
  pull_request:
    branches: [ "main" ]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'benchmarks/**'
  workflow_dispatch:

permissions:
  contents: read
  issues: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  DOTNET_VERSION: '9.0.x'
  DOTNET_NOLOGO: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true

jobs:
  quality-checks:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup .NET with Cache
        uses: ./.github/actions/setup-dotnet-cache
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Restore dependencies
        run: dotnet restore MarketDataCollector.sln /p:EnableWindowsTargeting=true

      # Format check (doesn't need build)
      - name: Check code formatting
        id: format-check
        run: dotnet format MarketDataCollector.sln --verify-no-changes --verbosity normal
        continue-on-error: true

      # Single build with all analysis enabled
      - name: Build with analysis and documentation
        id: build
        continue-on-error: true
        run: |
          set -o pipefail
          dotnet build MarketDataCollector.sln \
            -c Release \
            --no-restore \
            /p:EnableWindowsTargeting=true \
            /p:TreatWarningsAsErrors=false \
            /p:AnalysisLevel=latest \
            /p:EnforceCodeStyleInBuild=true \
            /p:RunAnalyzersDuringBuild=true \
            /p:GenerateDocumentationFile=true \
            /p:NoWarn=1591 \
            2>&1 | tee build-output.log

      # Analyze build output for issues
      - name: Analyze build results
        id: analyze
        if: always()
        run: |
          FORMAT_ISSUES=0
          BUILD_ISSUES=0
          WARNING_COUNT=0
          ERROR_COUNT=0

          if [ "${{ steps.format-check.outcome }}" != "success" ]; then
            FORMAT_ISSUES=1
          fi

          if [ -f build-output.log ]; then
            WARNING_COUNT=$(grep -cE "warning (CA|CS|IDE|SCS)" build-output.log || true)
            ERROR_COUNT=$(grep -cE " error (CA|CS|IDE|SCS)" build-output.log || true)
          fi

          if [ "${{ steps.build.outcome }}" != "success" ] || [ "$WARNING_COUNT" -gt 0 ] || [ "$ERROR_COUNT" -gt 0 ]; then
            BUILD_ISSUES=1
          fi

          HAS_ISSUES=0
          if [ "$FORMAT_ISSUES" -eq 1 ] || [ "$BUILD_ISSUES" -eq 1 ]; then
            HAS_ISSUES=1
          fi

          {
            echo "format_issues=$FORMAT_ISSUES"
            echo "build_issues=$BUILD_ISSUES"
            echo "warning_count=$WARNING_COUNT"
            echo "error_count=$ERROR_COUNT"
            echo "has_issues=$HAS_ISSUES"
          } >> "$GITHUB_OUTPUT"

          echo "## Code Quality Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Generated:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Format check results
          echo "### Code Formatting" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.format-check.outcome }}" = "success" ]; then
            echo "- Status: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "- Status: Issues detected" >> $GITHUB_STEP_SUMMARY
            echo "- Run \`dotnet format\` locally to fix" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          # Static analysis results
          echo "### Static Analysis" >> $GITHUB_STEP_SUMMARY
          ANALYZER_WARNINGS=$(grep -cE "warning (CA|CS|IDE)" build-output.log || true)
          echo "- Analyzer warnings: $ANALYZER_WARNINGS" >> $GITHUB_STEP_SUMMARY

          # Security warnings
          SECURITY_WARNINGS=$(grep -cE "warning SCS" build-output.log || true)
          if [ "$SECURITY_WARNINGS" -gt 0 ]; then
            echo "- Security warnings: $SECURITY_WARNINGS" >> $GITHUB_STEP_SUMMARY
          fi

          # Nullable warnings
          NULLABLE_WARNINGS=$(grep -cE "warning CS86" build-output.log || true)
          if [ "$NULLABLE_WARNINGS" -gt 0 ]; then
            echo "- Nullable reference warnings: $NULLABLE_WARNINGS" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          # XML documentation
          echo "### XML Documentation" >> $GITHUB_STEP_SUMMARY
          XML_COUNT=$(find . -name "*.xml" -path "*/bin/Release/*" 2>/dev/null | wc -l)
          echo "- Documentation files generated: $XML_COUNT" >> $GITHUB_STEP_SUMMARY

      - name: Upload build log
        if: always() && steps.analyze.outputs.has_issues == '1'
        uses: actions/upload-artifact@v4
        with:
          name: build-output
          path: build-output.log
          retention-days: 7

      - name: Create Copilot task for quality issues
        if: >-
          always() &&
          steps.analyze.outputs.has_issues == '1' &&
          github.event_name != 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const workflowName = context.workflow;
            const runId = context.runId;
            const sha = context.sha;
            const shortSha = sha.substring(0, 7);

            const title = `[Copilot Task] Resolve code quality issues (${shortSha})`;
            const body = [
              '## Copilot task',
              '',
              '@copilot please investigate and resolve the code quality issues reported by the workflow run below.',
              '',
              `- Workflow: ${workflowName}`,
              `- Run: https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${runId}`,
              `- Commit: ${sha}`,
              `- Format issues: ${{ steps.analyze.outputs.format_issues }}`,
              `- Build issues: ${{ steps.analyze.outputs.build_issues }}`,
              `- Warnings: ${{ steps.analyze.outputs.warning_count }}`,
              `- Errors: ${{ steps.analyze.outputs.error_count }}`,
              '',
              'Please submit a PR with fixes and link it to this issue.'
            ].join('\n');

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title,
              body,
              labels: ['copilot', 'code-quality']
            });

      - name: Fail workflow when quality issues exist
        if: steps.analyze.outputs.has_issues == '1'
        run: |
          echo "Code quality issues detected. Failing workflow after creating Copilot task."
          exit 1
