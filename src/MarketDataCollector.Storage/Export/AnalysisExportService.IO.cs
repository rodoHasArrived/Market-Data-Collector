using System.IO.Compression;
using System.Security.Cryptography;
using System.Text;
using System.Text.Json;

namespace MarketDataCollector.Storage.Export;

/// <summary>
/// Documentation generation, loader scripts, and I/O utility methods.
/// </summary>
public sealed partial class AnalysisExportService
{
    private async Task<string> GenerateDataDictionaryAsync(
        string outputDir,
        string[] eventTypes,
        ExportProfile profile,
        CancellationToken ct)
    {
        var dictPath = Path.Combine(outputDir, "data_dictionary.md");

        var sb = new StringBuilder();
        sb.AppendLine("# Data Dictionary");
        sb.AppendLine();
        sb.AppendLine($"Generated: {DateTime.UtcNow:yyyy-MM-dd HH:mm:ss} UTC");
        sb.AppendLine($"Export Profile: {profile.Name}");
        sb.AppendLine($"Format: {profile.Format}");
        sb.AppendLine();

        foreach (var eventType in eventTypes)
        {
            sb.AppendLine($"## {eventType} Event");
            sb.AppendLine();
            sb.AppendLine("| Field | Type | Description | Example |");
            sb.AppendLine("|-------|------|-------------|---------|");

            switch (eventType.ToLowerInvariant())
            {
                case "trade":
                    sb.AppendLine("| Timestamp | datetime64[ns] | Event timestamp in UTC | 2026-01-03T14:30:00.123456789Z |");
                    sb.AppendLine("| Symbol | string | Ticker symbol | AAPL |");
                    sb.AppendLine("| Price | decimal(18,8) | Trade price | 185.2500 |");
                    sb.AppendLine("| Size | int64 | Trade size in shares | 100 |");
                    sb.AppendLine("| Side | enum | Aggressor side (Buy/Sell/Unknown) | Buy |");
                    sb.AppendLine("| Exchange | string | Exchange code | XNAS |");
                    sb.AppendLine("| TradeId | string | Unique trade identifier | T123456789 |");
                    sb.AppendLine("| Conditions | string[] | Trade condition codes | [\"@\", \"F\"] |");
                    break;

                case "bboquote":
                case "quote":
                    sb.AppendLine("| Timestamp | datetime64[ns] | Event timestamp in UTC | 2026-01-03T14:30:00.123456789Z |");
                    sb.AppendLine("| Symbol | string | Ticker symbol | AAPL |");
                    sb.AppendLine("| BidPrice | decimal(18,8) | Best bid price | 185.2400 |");
                    sb.AppendLine("| BidSize | int64 | Bid size in shares | 500 |");
                    sb.AppendLine("| AskPrice | decimal(18,8) | Best ask price | 185.2600 |");
                    sb.AppendLine("| AskSize | int64 | Ask size in shares | 300 |");
                    sb.AppendLine("| Exchange | string | Exchange code | XNAS |");
                    break;
            }

            sb.AppendLine();
        }

        await File.WriteAllTextAsync(dictPath, sb.ToString(), ct);
        return dictPath;
    }

    private async Task<string> GenerateLoaderScriptAsync(
        string outputDir,
        ExportProfile profile,
        List<ExportedFile> files,
        CancellationToken ct)
    {
        string scriptPath;
        string script;

        switch (profile.TargetTool.ToLowerInvariant())
        {
            case "python":
                scriptPath = Path.Combine(outputDir, "load_data.py");
                script = GeneratePythonLoader(files, profile);
                break;
            case "pyarrow":
                scriptPath = Path.Combine(outputDir, "load_data.py");
                script = GeneratePyArrowLoader(files, profile);
                break;
            case "r":
                scriptPath = Path.Combine(outputDir, "load_data.R");
                script = GenerateRLoader(files, profile);
                break;
            case "postgresql":
                scriptPath = Path.Combine(outputDir, "load_data.sh");
                script = GeneratePostgresLoader(files, profile);
                break;
            default:
                return string.Empty;
        }

        await File.WriteAllTextAsync(scriptPath, script, ct);
        return scriptPath;
    }

    private string GeneratePythonLoader(List<ExportedFile> files, ExportProfile profile)
    {
        var sb = new StringBuilder();
        sb.AppendLine("#!/usr/bin/env python3");
        sb.AppendLine("\"\"\"");
        sb.AppendLine("Market Data Loader");
        sb.AppendLine($"Generated by MarketDataCollector - {profile.Name}");
        sb.AppendLine("\"\"\"");
        sb.AppendLine();
        sb.AppendLine("import pandas as pd");
        sb.AppendLine("from pathlib import Path");
        sb.AppendLine();
        sb.AppendLine("DATA_DIR = Path(__file__).parent");
        sb.AppendLine();

        if (profile.Format == ExportFormat.Parquet)
        {
            sb.AppendLine("""
def load_trades(symbol: str = None) -> pd.DataFrame:
    \"\"\"Load trade data into a pandas DataFrame.\"\"\"
    pattern = f"{symbol}_*.parquet" if symbol else "*.parquet"
    files = list(DATA_DIR.glob(pattern))
    if not files:
        raise FileNotFoundError(f"No parquet files found matching {pattern}")
    return pd.concat([pd.read_parquet(f) for f in files], ignore_index=True)


def load_quotes(symbol: str = None) -> pd.DataFrame:
    \"\"\"Load quote data into a pandas DataFrame.\"\"\"
    pattern = f"{symbol}_*.parquet" if symbol else "*quote*.parquet"
    files = list(DATA_DIR.glob(pattern))
    if not files:
        raise FileNotFoundError(f"No quote files found matching {pattern}")
    return pd.concat([pd.read_parquet(f) for f in files], ignore_index=True)

""");
        }
        else if (profile.Format == ExportFormat.Csv)
        {
            sb.AppendLine("""
def load_trades(symbol: str = None) -> pd.DataFrame:
    \"\"\"Load trade data into a pandas DataFrame.\"\"\"
    pattern = f"{symbol}_*.csv" if symbol else "*.csv"
    files = list(DATA_DIR.glob(pattern))
    if not files:
        raise FileNotFoundError(f"No CSV files found matching {pattern}")
    return pd.concat([pd.read_csv(f, parse_dates=['Timestamp']) for f in files], ignore_index=True)

""");
        }

        sb.AppendLine("""
if __name__ == "__main__":
    # Example usage
    df = load_trades()
    print(f"Loaded {len(df):,} records")
    print(df.head())
""");

        return sb.ToString();
    }

    private string GeneratePyArrowLoader(List<ExportedFile> files, ExportProfile profile)
    {
        var sb = new StringBuilder();
        sb.AppendLine("#!/usr/bin/env python3");
        sb.AppendLine("\"\"\"");
        sb.AppendLine("Market Data Loader - Apache Arrow / Feather");
        sb.AppendLine($"Generated by MarketDataCollector - {profile.Name}");
        sb.AppendLine("\"\"\"");
        sb.AppendLine();
        sb.AppendLine("import pyarrow as pa");
        sb.AppendLine("import pyarrow.ipc as ipc");
        sb.AppendLine("import pandas as pd");
        sb.AppendLine("from pathlib import Path");
        sb.AppendLine();
        sb.AppendLine("DATA_DIR = Path(__file__).parent");
        sb.AppendLine();
        sb.AppendLine("""
def load_arrow(symbol: str = None) -> pa.Table:
    \"\"\"Load Arrow IPC files into a PyArrow Table (zero-copy).\"\"\"
    pattern = f"{symbol}_*.arrow" if symbol else "*.arrow"
    files = sorted(DATA_DIR.glob(pattern))
    if not files:
        raise FileNotFoundError(f"No Arrow files found matching {pattern}")
    tables = []
    for f in files:
        reader = ipc.open_file(f)
        tables.append(reader.read_all())
    return pa.concat_tables(tables)


def load_dataframe(symbol: str = None) -> pd.DataFrame:
    \"\"\"Load Arrow IPC files into a pandas DataFrame.\"\"\"
    return load_arrow(symbol).to_pandas()


if __name__ == "__main__":
    table = load_arrow()
    print(f"Schema: {table.schema}")
    print(f"Rows: {table.num_rows:,}")
    df = table.to_pandas()
    print(df.head())
""");

        return sb.ToString();
    }

    private string GenerateRLoader(List<ExportedFile> files, ExportProfile profile)
    {
        var sb = new StringBuilder();
        sb.AppendLine("# Market Data Loader");
        sb.AppendLine($"# Generated by MarketDataCollector - {profile.Name}");
        sb.AppendLine();
        sb.AppendLine("library(tidyverse)");
        sb.AppendLine("library(lubridate)");
        sb.AppendLine();
        sb.AppendLine("data_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)");
        sb.AppendLine();
        sb.AppendLine("""
load_trades <- function(symbol = NULL) {
  pattern <- if (!is.null(symbol)) paste0(symbol, "_.*\\.csv$") else ".*\\.csv$"
  files <- list.files(data_dir, pattern = pattern, full.names = TRUE)

  if (length(files) == 0) {
    stop("No CSV files found")
  }

  df <- files %>%
    map_dfr(read_csv) %>%
    mutate(Timestamp = ymd_hms(Timestamp))

  return(df)
}

# Example usage
# trades <- load_trades("AAPL")
# head(trades)
""");

        return sb.ToString();
    }

    private string GeneratePostgresLoader(List<ExportedFile> files, ExportProfile profile)
    {
        var sb = new StringBuilder();
        sb.AppendLine("#!/bin/bash");
        sb.AppendLine("# Market Data PostgreSQL Loader");
        sb.AppendLine($"# Generated by MarketDataCollector - {profile.Name}");
        sb.AppendLine();
        sb.AppendLine("DB_NAME=${1:-marketdata}");
        sb.AppendLine("DB_USER=${2:-postgres}");
        sb.AppendLine("SCRIPT_DIR=$(dirname \"$0\")");
        sb.AppendLine();
        sb.AppendLine("# Create tables");
        sb.AppendLine("psql -U $DB_USER -d $DB_NAME -f \"$SCRIPT_DIR/create_tables.sql\"");
        sb.AppendLine();
        sb.AppendLine("# Load data");

        foreach (var file in files.Where(f => f.Format == "csv"))
        {
            var tableName = $"market_{file.EventType?.ToLowerInvariant() ?? "data"}";
            sb.AppendLine($"psql -U $DB_USER -d $DB_NAME -c \"\\copy {tableName} FROM '$SCRIPT_DIR/{file.RelativePath}' WITH CSV HEADER\"");
        }

        sb.AppendLine();
        sb.AppendLine("echo \"Data loaded successfully\"");

        return sb.ToString();
    }

    /// <summary>
    /// Generates a machine-readable lineage manifest alongside the export, documenting
    /// data provenance, quality scores, and known gaps for reproducibility and audit.
    /// </summary>
    internal async Task<string> GenerateLineageManifestAsync(
        string outputDir,
        ExportRequest request,
        ExportResult result,
        CancellationToken ct)
    {
        var manifestPath = Path.Combine(outputDir, "lineage_manifest.json");

        // Build per-file lineage entries
        var fileEntries = result.Files.Select(f => new
        {
            path = f.RelativePath,
            symbol = f.Symbol,
            eventType = f.EventType,
            format = f.Format,
            recordCount = f.RecordCount,
            sizeBytes = f.SizeBytes,
            checksumSha256 = f.ChecksumSha256,
            firstTimestamp = f.FirstTimestamp,
            lastTimestamp = f.LastTimestamp
        }).ToArray();

        var manifest = new
        {
            schemaVersion = "1.0",
            exportedAt = DateTime.UtcNow.ToString("O"),
            generator = "MarketDataCollector.AnalysisExportService",
            export = new
            {
                profileId = result.ProfileId,
                format = result.Files.FirstOrDefault()?.Format ?? "unknown",
                symbols = result.Symbols,
                dateRange = result.DateRange is not null
                    ? new { from = result.DateRange.Start.ToString("yyyy-MM-dd"), to = result.DateRange.End.ToString("yyyy-MM-dd"), tradingDays = result.DateRange.TradingDays }
                    : null,
                totalRecords = result.TotalRecords,
                totalBytes = result.TotalBytes,
                filesGenerated = result.FilesGenerated,
                durationSeconds = Math.Round(result.DurationSeconds, 2)
            },
            source = new
            {
                dataRoot = _dataRoot,
                requestedSymbols = request.Symbols ?? Array.Empty<string>(),
                requestedEventTypes = request.EventTypes,
                startDate = request.StartDate.ToString("O"),
                endDate = request.EndDate.ToString("O"),
                sessionFilter = request.SessionFilter.ToString(),
                minQualityScore = request.MinQualityScore
            },
            quality = result.QualitySummary is not null
                ? new
                {
                    overallScore = result.QualitySummary.OverallScore,
                    completenessScore = result.QualitySummary.CompletenessScore,
                    gapsDetected = result.QualitySummary.GapsDetected,
                    gapsFilled = result.QualitySummary.GapsFilled,
                    outliersDetected = result.QualitySummary.OutliersDetected,
                    missingDates = result.QualitySummary.MissingDates
                }
                : null,
            files = fileEntries,
            warnings = result.Warnings
        };

        var json = JsonSerializer.Serialize(manifest, new JsonSerializerOptions
        {
            WriteIndented = true,
            DefaultIgnoreCondition = System.Text.Json.Serialization.JsonIgnoreCondition.WhenWritingNull
        });

        await File.WriteAllTextAsync(manifestPath, json, ct);
        return manifestPath;
    }

    private async IAsyncEnumerable<Dictionary<string, object?>> ReadJsonlRecordsAsync(
        string path,
        [System.Runtime.CompilerServices.EnumeratorCancellation] CancellationToken ct)
    {
        Stream stream = File.OpenRead(path);
        if (path.EndsWith(".gz", StringComparison.OrdinalIgnoreCase))
        {
            stream = new GZipStream(stream, CompressionMode.Decompress);
        }

        await using (stream)
        using (var reader = new StreamReader(stream))
        {
            while (!reader.EndOfStream && !ct.IsCancellationRequested)
            {
                var line = await reader.ReadLineAsync();
                if (string.IsNullOrWhiteSpace(line)) continue;

                var doc = JsonDocument.Parse(line);
                var dict = new Dictionary<string, object?>();

                foreach (var prop in doc.RootElement.EnumerateObject())
                {
                    dict[prop.Name] = prop.Value.ValueKind switch
                    {
                        JsonValueKind.String => prop.Value.GetString(),
                        JsonValueKind.Number => prop.Value.GetDouble(),
                        JsonValueKind.True => true,
                        JsonValueKind.False => false,
                        JsonValueKind.Null => null,
                        _ => prop.Value.GetRawText()
                    };
                }

                yield return dict;
            }
        }
    }

    private async Task<long> CountRecordsAsync(string path, CancellationToken ct)
    {
        long count = 0;
        await foreach (var _ in ReadJsonlRecordsAsync(path, ct))
        {
            count++;
        }
        return count;
    }

    private async Task<string> ComputeChecksumAsync(string path, CancellationToken ct)
    {
        await using var stream = File.OpenRead(path);
        var hash = await SHA256.HashDataAsync(stream, ct);
        return Convert.ToHexString(hash).ToLowerInvariant();
    }

    private static string EscapeCsvValue(string value)
    {
        if (value.Contains(',') || value.Contains('"') || value.Contains('\n'))
        {
            return $"\"{value.Replace("\"", "\"\"")}\"";
        }
        return value;
    }

    private static string SqlEscape(object? value)
    {
        if (value == null) return "NULL";
        if (value is string s) return $"'{s.Replace("'", "''")}'";
        if (value is bool b) return b ? "TRUE" : "FALSE";
        if (value is DateTime dt) return $"'{dt:yyyy-MM-dd HH:mm:ss.ffffff}'";
        return value.ToString() ?? "NULL";
    }
}
