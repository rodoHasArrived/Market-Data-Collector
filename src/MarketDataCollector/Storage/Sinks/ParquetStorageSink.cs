using System.Collections.Concurrent;
using System.Threading;
using MarketDataCollector.Application.Logging;
using MarketDataCollector.Application.Monitoring;
using MarketDataCollector.Contracts.Domain.Models;
using MarketDataCollector.Domain.Events;
using MarketDataCollector.Domain.Models;
using MarketDataCollector.Storage.Interfaces;
using MarketDataCollector.Storage.Services;
using Parquet;
using Parquet.Data;
using Parquet.Schema;
using Serilog;

namespace MarketDataCollector.Storage.Sinks;

/// <summary>
/// Apache Parquet storage sink for high-performance columnar storage.
/// Provides 10-20x better compression than JSONL and optimized for analytics.
///
/// Based on: https://github.com/aloneguid/parquet-dotnet (MIT)
/// Reference: docs/open-source-references.md #20
/// </summary>
public sealed class ParquetStorageSink : IStorageSink
{
    private readonly ILogger _log = LoggingSetup.ForContext<ParquetStorageSink>();
    private readonly StorageOptions _options;
    private readonly ParquetStorageOptions _parquetOptions;
    private readonly ConcurrentDictionary<string, MarketEventBuffer> _buffers = new(StringComparer.OrdinalIgnoreCase);
    private readonly Timer _flushTimer;
    private readonly CancellationTokenSource _disposalCts = new();
    private readonly SemaphoreSlim _flushGate = new(1, 1);
    private int _disposed;

    // Trade event schema
    private static readonly ParquetSchema TradeSchema = new(
        new DataField<DateTimeOffset>("Timestamp"),
        new DataField<string>("Symbol"),
        new DataField<decimal>("Price"),
        new DataField<long>("Size"),
        new DataField<string>("AggressorSide"),
        new DataField<long>("SequenceNumber"),
        new DataField<string>("Venue"),
        new DataField<string>("Source")
    );

    // Quote event schema
    private static readonly ParquetSchema QuoteSchema = new(
        new DataField<DateTimeOffset>("Timestamp"),
        new DataField<string>("Symbol"),
        new DataField<decimal>("BidPrice"),
        new DataField<long>("BidSize"),
        new DataField<decimal>("AskPrice"),
        new DataField<long>("AskSize"),
        new DataField<decimal>("Spread"),
        new DataField<long>("SequenceNumber"),
        new DataField<string>("Source")
    );

    // L2 Snapshot schema
    private static readonly ParquetSchema L2Schema = new(
        new DataField<DateTimeOffset>("Timestamp"),
        new DataField<string>("Symbol"),
        new DataField<int>("BidLevels"),
        new DataField<int>("AskLevels"),
        new DataField<decimal>("BestBid"),
        new DataField<decimal>("BestAsk"),
        new DataField<decimal?>("Spread"),
        new DataField<long>("SequenceNumber"),
        new DataField<string>("Source"),
        new DataField<string>("BidsJson"),
        new DataField<string>("AsksJson")
    );

    // Historical bar schema
    private static readonly ParquetSchema BarSchema = new(
        new DataField<DateTimeOffset>("Timestamp"),
        new DataField<string>("Symbol"),
        new DataField<decimal>("Open"),
        new DataField<decimal>("High"),
        new DataField<decimal>("Low"),
        new DataField<decimal>("Close"),
        new DataField<decimal>("Volume"),
        new DataField<long>("SequenceNumber"),
        new DataField<string>("Source")
    );

    public ParquetStorageSink(StorageOptions options, ParquetStorageOptions? parquetOptions = null)
    {
        _options = options ?? throw new ArgumentNullException(nameof(options));
        _parquetOptions = parquetOptions ?? ParquetStorageOptions.Default;

        // Setup periodic flush timer with safe async wrapper to prevent silent data loss
        _flushTimer = new Timer(
            _ => FlushAllBuffersSafelyAsync(),
            null,
            _parquetOptions.FlushInterval,
            _parquetOptions.FlushInterval);

        _log.Information("ParquetStorageSink initialized with buffer size {BufferSize}, flush interval {FlushInterval}s",
            _parquetOptions.BufferSize, _parquetOptions.FlushInterval.TotalSeconds);
    }

    public async ValueTask AppendAsync(MarketEvent evt, CancellationToken ct = default)
    {
        if (Volatile.Read(ref _disposed) != 0) throw new ObjectDisposedException(nameof(ParquetStorageSink));

        EventSchemaValidator.Validate(evt);

        var bufferKey = GetBufferKey(evt);
        var buffer = _buffers.GetOrAdd(bufferKey, _ => new MarketEventBuffer(_parquetOptions.BufferSize));

        buffer.Add(evt);

        // Flush if buffer is full
        if (buffer.ShouldFlush(_parquetOptions.BufferSize))
        {
            await FlushBufferAsync(bufferKey, buffer, ct);
        }
    }

    public async Task FlushAsync(CancellationToken ct = default)
    {
        await FlushAllBuffersAsync(ct);
    }

    private async void FlushAllBuffersSafelyAsync()
    {
        try
        {
            await FlushAllBuffersAsync(_disposalCts.Token).ConfigureAwait(false);
        }
        catch (OperationCanceledException) when (_disposalCts.IsCancellationRequested)
        {
            // Disposal in progress, stop flushing
        }
        catch (Exception ex)
        {
            _log.Error(ex, "Periodic Parquet flush failed — {BufferCount} buffers may contain unflushed data", _buffers.Count);
        }
    }

    private async Task FlushAllBuffersAsync(CancellationToken ct = default)
    {
        await _flushGate.WaitAsync(ct).ConfigureAwait(false);
        try
        {
            foreach (var kvp in _buffers)
            {
                if (kvp.Value.Count > 0)
                {
                    await FlushBufferAsync(kvp.Key, kvp.Value, ct);
                }
            }
        }
        finally
        {
            _flushGate.Release();
        }
    }

    private async Task FlushBufferAsync(string bufferKey, MarketEventBuffer buffer, CancellationToken ct)
    {
        var events = buffer.DrainAll().ToList();
        if (events.Count == 0) return;

        try
        {
            var path = GetFilePath(events[0]);
            Directory.CreateDirectory(Path.GetDirectoryName(path)!);

            var eventType = events[0].Type;

            switch (eventType)
            {
                case MarketEventType.Trade:
                    await WriteTradesAsync(path, events, ct);
                    break;
                case MarketEventType.BboQuote:
                    await WriteQuotesAsync(path, events, ct);
                    break;
                case MarketEventType.L2Snapshot:
                    await WriteL2SnapshotsAsync(path, events, ct);
                    break;
                case MarketEventType.HistoricalBar:
                    await WriteBarsAsync(path, events, ct);
                    break;
                default:
                    // Write as generic event
                    await WriteGenericEventsAsync(path, events, ct);
                    break;
            }

            _log.Debug("Flushed {Count} events to Parquet file: {Path}", events.Count, path);
        }
        catch (Exception ex)
        {
            _log.Error(ex, "Failed to flush {Count} events to Parquet", events.Count);
            throw;
        }
    }

    private async Task WriteTradesAsync(string path, List<MarketEvent> events, CancellationToken ct)
    {
        // Count valid trades first to size arrays exactly
        var count = 0;
        for (var i = 0; i < events.Count; i++)
        {
            if (events[i].Payload is Trade) count++;
        }

        if (count == 0) return;

        // Single-pass: build all column arrays simultaneously
        var timestamps = new DateTimeOffset[count];
        var symbols = new string[count];
        var prices = new decimal[count];
        var sizes = new long[count];
        var aggressors = new string[count];
        var sequences = new long[count];
        var venues = new string[count];
        var sources = new string[count];

        var idx = 0;
        for (var i = 0; i < events.Count; i++)
        {
            if (events[i].Payload is not Trade trade) continue;
            var evt = events[i];
            timestamps[idx] = evt.Timestamp;
            symbols[idx] = evt.Symbol;
            prices[idx] = trade.Price;
            sizes[idx] = trade.Size;
            aggressors[idx] = trade.Aggressor.ToString();
            sequences[idx] = trade.SequenceNumber;
            venues[idx] = trade.Venue ?? "UNKNOWN";
            sources[idx] = evt.Source;
            idx++;
        }

        using var groupWriter = await ParquetWriter.CreateAsync(TradeSchema, File.Create(path));
        using var rowGroupWriter = groupWriter.CreateRowGroup();

        await rowGroupWriter.WriteColumnAsync(new DataColumn(TradeSchema.DataFields[0], timestamps));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(TradeSchema.DataFields[1], symbols));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(TradeSchema.DataFields[2], prices));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(TradeSchema.DataFields[3], sizes));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(TradeSchema.DataFields[4], aggressors));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(TradeSchema.DataFields[5], sequences));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(TradeSchema.DataFields[6], venues));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(TradeSchema.DataFields[7], sources));
    }

    private async Task WriteQuotesAsync(string path, List<MarketEvent> events, CancellationToken ct)
    {
        var count = 0;
        for (var i = 0; i < events.Count; i++)
        {
            if (events[i].Payload is BboQuotePayload) count++;
        }

        if (count == 0) return;

        var timestamps = new DateTimeOffset[count];
        var symbols = new string[count];
        var bidPrices = new decimal[count];
        var bidSizes = new long[count];
        var askPrices = new decimal[count];
        var askSizes = new long[count];
        var spreads = new decimal[count];
        var sequences = new long[count];
        var sources = new string[count];

        var idx = 0;
        for (var i = 0; i < events.Count; i++)
        {
            if (events[i].Payload is not BboQuotePayload quote) continue;
            var evt = events[i];
            timestamps[idx] = evt.Timestamp;
            symbols[idx] = evt.Symbol;
            bidPrices[idx] = quote.BidPrice;
            bidSizes[idx] = quote.BidSize;
            askPrices[idx] = quote.AskPrice;
            askSizes[idx] = quote.AskSize;
            spreads[idx] = quote.Spread ?? 0m;
            sequences[idx] = quote.SequenceNumber;
            sources[idx] = evt.Source;
            idx++;
        }

        using var groupWriter = await ParquetWriter.CreateAsync(QuoteSchema, File.Create(path));
        using var rowGroupWriter = groupWriter.CreateRowGroup();

        await rowGroupWriter.WriteColumnAsync(new DataColumn(QuoteSchema.DataFields[0], timestamps));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(QuoteSchema.DataFields[1], symbols));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(QuoteSchema.DataFields[2], bidPrices));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(QuoteSchema.DataFields[3], bidSizes));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(QuoteSchema.DataFields[4], askPrices));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(QuoteSchema.DataFields[5], askSizes));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(QuoteSchema.DataFields[6], spreads));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(QuoteSchema.DataFields[7], sequences));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(QuoteSchema.DataFields[8], sources));
    }

    private async Task WriteL2SnapshotsAsync(string path, List<MarketEvent> events, CancellationToken ct)
    {
        var snapshots = events
            .Select(e => (Event: e, Data: ExtractL2Data(e)))
            .Where(x => x.Data.Snapshot is not null)
            .Select(x => (x.Event, Snapshot: x.Data.Snapshot!, x.Data.SequenceNumber))
            .ToList();

        if (snapshots.Count is 0) return;

        using var groupWriter = await ParquetWriter.CreateAsync(L2Schema, File.Create(path));
        using var rowGroupWriter = groupWriter.CreateRowGroup();

        await rowGroupWriter.WriteColumnAsync(new DataColumn(L2Schema.DataFields[0], snapshots.Select(s => s.Event.Timestamp).ToArray()));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(L2Schema.DataFields[1], snapshots.Select(s => s.Event.Symbol).ToArray()));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(L2Schema.DataFields[2], snapshots.Select(s => s.Snapshot.Bids?.Count ?? 0).ToArray()));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(L2Schema.DataFields[3], snapshots.Select(s => s.Snapshot.Asks?.Count ?? 0).ToArray()));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(L2Schema.DataFields[4], snapshots.Select(s => s.Snapshot.Bids?.FirstOrDefault()?.Price ?? 0m).ToArray()));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(L2Schema.DataFields[5], snapshots.Select(s => s.Snapshot.Asks?.FirstOrDefault()?.Price ?? 0m).ToArray()));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(L2Schema.DataFields[6], snapshots.Select(s => ComputeSpread(s.Snapshot)).ToArray()));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(L2Schema.DataFields[7], snapshots.Select(s => s.SequenceNumber).ToArray()));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(L2Schema.DataFields[8], snapshots.Select(s => s.Event.Source).ToArray()));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(L2Schema.DataFields[9], snapshots.Select(s => System.Text.Json.JsonSerializer.Serialize(s.Snapshot.Bids ?? (IReadOnlyList<OrderBookLevel>)[])).ToArray()));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(L2Schema.DataFields[10], snapshots.Select(s => System.Text.Json.JsonSerializer.Serialize(s.Snapshot.Asks ?? (IReadOnlyList<OrderBookLevel>)[])).ToArray()));
    }

    private static (LOBSnapshot? Snapshot, long SequenceNumber) ExtractL2Data(MarketEvent evt) => evt.Payload switch
    {
        L2SnapshotPayload l2 => (l2.Snapshot, l2.SequenceNumber),
        LOBSnapshot lob => (lob, lob.SequenceNumber),
        _ => (null, 0)
    };

    private static decimal? ComputeSpread(LOBSnapshot snap)
    {
        var bestBid = snap.Bids?.FirstOrDefault()?.Price ?? 0;
        var bestAsk = snap.Asks?.FirstOrDefault()?.Price ?? 0;
        return bestBid > 0 && bestAsk > 0 ? bestAsk - bestBid : null;
    }

    private async Task WriteBarsAsync(string path, List<MarketEvent> events, CancellationToken ct)
    {
        var count = 0;
        for (var i = 0; i < events.Count; i++)
        {
            if (events[i].Payload is HistoricalBar) count++;
        }

        if (count == 0) return;

        var timestamps = new DateTimeOffset[count];
        var symbols = new string[count];
        var opens = new decimal[count];
        var highs = new decimal[count];
        var lows = new decimal[count];
        var closes = new decimal[count];
        var volumes = new decimal[count];
        var sequences = new long[count];
        var sources = new string[count];

        var idx = 0;
        for (var i = 0; i < events.Count; i++)
        {
            if (events[i].Payload is not HistoricalBar bar) continue;
            var evt = events[i];
            timestamps[idx] = evt.Timestamp;
            symbols[idx] = evt.Symbol;
            opens[idx] = bar.Open;
            highs[idx] = bar.High;
            lows[idx] = bar.Low;
            closes[idx] = bar.Close;
            volumes[idx] = bar.Volume;
            sequences[idx] = bar.SequenceNumber;
            sources[idx] = evt.Source;
            idx++;
        }

        using var groupWriter = await ParquetWriter.CreateAsync(BarSchema, File.Create(path));
        using var rowGroupWriter = groupWriter.CreateRowGroup();

        await rowGroupWriter.WriteColumnAsync(new DataColumn(BarSchema.DataFields[0], timestamps));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(BarSchema.DataFields[1], symbols));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(BarSchema.DataFields[2], opens));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(BarSchema.DataFields[3], highs));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(BarSchema.DataFields[4], lows));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(BarSchema.DataFields[5], closes));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(BarSchema.DataFields[6], volumes));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(BarSchema.DataFields[7], sequences));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(BarSchema.DataFields[8], sources));
    }

    private async Task WriteGenericEventsAsync(string path, List<MarketEvent> events, CancellationToken ct)
    {
        // For generic events, write as JSON strings in a simple schema
        var genericSchema = new ParquetSchema(
            new DataField<DateTimeOffset>("Timestamp"),
            new DataField<string>("Symbol"),
            new DataField<string>("Type"),
            new DataField<string>("PayloadJson"),
            new DataField<long>("Sequence"),
            new DataField<string>("Source")
        );

        var timestamps = events.Select(e => e.Timestamp).ToArray();
        var symbols = events.Select(e => e.Symbol).ToArray();
        var types = events.Select(e => e.Type.ToString()).ToArray();
        var payloads = events.Select(e => System.Text.Json.JsonSerializer.Serialize(e.Payload)).ToArray();
        var sequences = events.Select(e => e.Sequence).ToArray();
        var sources = events.Select(e => e.Source).ToArray();

        using var groupWriter = await ParquetWriter.CreateAsync(genericSchema, File.Create(path));
        using var rowGroupWriter = groupWriter.CreateRowGroup();

        await rowGroupWriter.WriteColumnAsync(new DataColumn(genericSchema.DataFields[0], timestamps));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(genericSchema.DataFields[1], symbols));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(genericSchema.DataFields[2], types));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(genericSchema.DataFields[3], payloads));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(genericSchema.DataFields[4], sequences));
        await rowGroupWriter.WriteColumnAsync(new DataColumn(genericSchema.DataFields[5], sources));
    }

    private string GetBufferKey(MarketEvent evt)
    {
        return $"{evt.Symbol}_{evt.Type}_{evt.Timestamp.Date:yyyyMMdd}";
    }

    private string GetFilePath(MarketEvent evt)
    {
        var date = evt.Timestamp.Date;
        var typeName = evt.Type.ToString().ToLowerInvariant();
        var fileName = $"{evt.Symbol}_{typeName}_{date:yyyyMMdd}.parquet";

        return _options.NamingConvention switch
        {
            FileNamingConvention.BySymbol => Path.Combine(_options.RootPath, evt.Symbol, fileName),
            FileNamingConvention.ByDate => Path.Combine(_options.RootPath, $"{date:yyyy}", $"{date:MM}", $"{date:dd}", fileName),
            FileNamingConvention.ByType => Path.Combine(_options.RootPath, typeName, fileName),
            _ => Path.Combine(_options.RootPath, fileName)
        };
    }

    public async ValueTask DisposeAsync()
    {
        if (Interlocked.Exchange(ref _disposed, 1) != 0) return;

        // 1. Signal cancellation to stop any in-flight timer callbacks
        _disposalCts.Cancel();

        // 2. Dispose timer — waits for any pending callback to complete
        await _flushTimer.DisposeAsync().ConfigureAwait(false);

        // 3. Final flush — guaranteed no concurrent timer flushes after timer disposal
        try
        {
            await _flushGate.WaitAsync().ConfigureAwait(false);
            try
            {
                foreach (var kvp in _buffers)
                {
                    if (kvp.Value.Count > 0)
                    {
                        await FlushBufferAsync(kvp.Key, kvp.Value, CancellationToken.None);
                    }
                }
            }
            finally
            {
                _flushGate.Release();
            }
        }
        catch (Exception ex)
        {
            _log.Error(ex, "Final buffer flush during disposal failed");
        }

        _buffers.Clear();
        _flushGate.Dispose();
        _disposalCts.Dispose();

        _log.Information("ParquetStorageSink disposed");
    }
}

/// <summary>
/// Configuration options for Parquet storage.
/// </summary>
public sealed class ParquetStorageOptions
{
    /// <summary>
    /// Number of events to buffer before writing to disk.
    /// </summary>
    public int BufferSize { get; init; } = 10000;

    /// <summary>
    /// Maximum time between flushes.
    /// </summary>
    public TimeSpan FlushInterval { get; init; } = TimeSpan.FromSeconds(30);

    /// <summary>
    /// Compression method for Parquet files.
    /// </summary>
    public CompressionMethod CompressionMethod { get; init; } = CompressionMethod.Snappy;

    /// <summary>
    /// Row group size for Parquet files.
    /// </summary>
    public int RowGroupSize { get; init; } = 50000;

    public static ParquetStorageOptions Default => new();

    public static ParquetStorageOptions HighCompression => new()
    {
        CompressionMethod = CompressionMethod.Gzip,
        BufferSize = 50000
    };

    public static ParquetStorageOptions LowLatency => new()
    {
        BufferSize = 1000,
        FlushInterval = TimeSpan.FromSeconds(5),
        CompressionMethod = CompressionMethod.None
    };
}
