using System.Threading.Channels;
using FluentAssertions;
using MarketDataCollector.Application.Pipeline;
using MarketDataCollector.Contracts.Domain.Enums;
using MarketDataCollector.Contracts.Domain.Models;
using MarketDataCollector.Domain.Events;
using MarketDataCollector.Domain.Models;
using MarketDataCollector.Storage.Interfaces;
using Moq;
using Xunit;

namespace MarketDataCollector.Tests.Pipeline;

/// <summary>
/// Integration tests for the EventPipeline with mock storage sinks.
/// Tests backpressure, throughput, statistics, and lifecycle management.
/// </summary>
public class EventPipelineTests : IAsyncLifetime
{
    private MockStorageSink _mockSink = null!;
    private EventPipeline _pipeline = null!;

    public Task InitializeAsync()
    {
        _mockSink = new MockStorageSink();
        _pipeline = new EventPipeline(
            _mockSink,
            capacity: 1000,
            flushInterval: TimeSpan.FromMilliseconds(100),
            enablePeriodicFlush: false); // Disable for deterministic testing
        return Task.CompletedTask;
    }

    public async Task DisposeAsync()
    {
        await _pipeline.DisposeAsync();
    }

    #region Basic Publishing Tests

    [Fact]
    public async Task TryPublish_SingleEvent_EventIsConsumed()
    {
        // Arrange
        var trade = CreateTradeEvent("SPY");

        // Act
        var published = _pipeline.TryPublish(trade);

        // Allow consumer to process
        await WaitForConsumption(expectedCount: 1);

        // Assert
        published.Should().BeTrue();
        _mockSink.ReceivedEvents.Should().ContainSingle()
            .Which.Symbol.Should().Be("SPY");
    }

    [Fact]
    public async Task TryPublish_MultipleEvents_AllEventsConsumed()
    {
        // Arrange
        var events = Enumerable.Range(0, 100)
            .Select(i => CreateTradeEvent($"SYM{i}"))
            .ToList();

        // Act
        foreach (var evt in events)
        {
            _pipeline.TryPublish(evt);
        }

        await WaitForConsumption(expectedCount: 100);

        // Assert
        _mockSink.ReceivedEvents.Should().HaveCount(100);
    }

    [Fact]
    public async Task PublishAsync_SingleEvent_EventIsConsumed()
    {
        // Arrange
        var trade = CreateTradeEvent("AAPL");

        // Act
        await _pipeline.PublishAsync(trade);
        await WaitForConsumption(expectedCount: 1);

        // Assert
        _mockSink.ReceivedEvents.Should().ContainSingle()
            .Which.Symbol.Should().Be("AAPL");
    }

    [Fact]
    public async Task TryPublish_DifferentEventTypes_AllTypesHandled()
    {
        // Arrange
        var trade = CreateTradeEvent("SPY");
        var quote = CreateQuoteEvent("SPY");

        // Act
        _pipeline.TryPublish(trade);
        _pipeline.TryPublish(quote);

        await WaitForConsumption(expectedCount: 2);

        // Assert
        _mockSink.ReceivedEvents.Should().HaveCount(2);
        _mockSink.ReceivedEvents.Should().Contain(e => e.Type == MarketEventType.Trade);
        _mockSink.ReceivedEvents.Should().Contain(e => e.Type == MarketEventType.BboQuote);
    }

    #endregion

    #region Statistics Tests

    [Fact]
    public async Task Statistics_AfterPublishing_TracksCounts()
    {
        // Arrange
        for (int i = 0; i < 50; i++)
        {
            _pipeline.TryPublish(CreateTradeEvent("SPY"));
        }

        await WaitForConsumption(expectedCount: 50);

        // Act
        var stats = _pipeline.GetStatistics();

        // Assert
        stats.PublishedCount.Should().Be(50);
        stats.ConsumedCount.Should().Be(50);
        stats.DroppedCount.Should().Be(0);
    }

    [Fact]
    public void PublishedCount_Increments_OnSuccessfulPublish()
    {
        // Arrange & Act
        _pipeline.TryPublish(CreateTradeEvent("SPY"));
        _pipeline.TryPublish(CreateTradeEvent("AAPL"));
        _pipeline.TryPublish(CreateTradeEvent("GOOGL"));

        // Assert
        _pipeline.PublishedCount.Should().Be(3);
    }

    [Fact]
    public async Task ConsumedCount_Increments_AsEventsAreProcessed()
    {
        // Arrange
        for (int i = 0; i < 10; i++)
        {
            _pipeline.TryPublish(CreateTradeEvent("SPY"));
        }

        // Act
        await WaitForConsumption(expectedCount: 10);

        // Assert
        _pipeline.ConsumedCount.Should().Be(10);
    }

    [Fact]
    public async Task AverageProcessingTimeUs_Calculated_AfterProcessing()
    {
        // Arrange
        for (int i = 0; i < 100; i++)
        {
            _pipeline.TryPublish(CreateTradeEvent("SPY"));
        }

        await WaitForConsumption(expectedCount: 100);

        // Act
        var avgTime = _pipeline.AverageProcessingTimeUs;

        // Assert
        avgTime.Should().BeGreaterThan(0);
    }

    [Fact(Skip = "Timing-sensitive test that is flaky in CI - the consumer may drain the queue before utilization can be measured")]
    public async Task QueueUtilization_ReflectsQueueFill()
    {
        // Arrange - Create pipeline with small capacity
        await using var sink = new MockStorageSink { ProcessingDelay = TimeSpan.FromMilliseconds(1000) };
        await using var pipeline = new EventPipeline(sink, capacity: 100, enablePeriodicFlush: false);

        // Act - Fill the queue
        for (int i = 0; i < 50; i++)
        {
            pipeline.TryPublish(CreateTradeEvent("SPY"));
        }

        // Assert
        pipeline.QueueUtilization.Should().BeGreaterThan(0);
    }

    [Fact]
    public async Task PeakQueueSize_TracksHighWaterMark()
    {
        // Arrange - Use a slow consumer so events queue up
        await using var sink = new MockStorageSink { ProcessingDelay = TimeSpan.FromMilliseconds(50) };
        await using var pipeline = new EventPipeline(sink, capacity: 1000, enablePeriodicFlush: false);

        // Act - Publish events faster than they can be consumed
        for (int i = 0; i < 100; i++)
        {
            pipeline.TryPublish(CreateTradeEvent("SPY"));
        }

        // Wait until at least some events are consumed (proves pipeline ran)
        var sw = System.Diagnostics.Stopwatch.StartNew();
        while (pipeline.ConsumedCount < 1 && sw.ElapsedMilliseconds < 2000)
        {
            await Task.Delay(1);
        }

        // Assert - Peak should have been recorded when events were queued
        pipeline.PeakQueueSize.Should().BeGreaterThan(0);
    }

    #endregion

    #region Backpressure Tests

    [Fact]
    public async Task TryPublish_WhenQueueFull_DropOldestMode_DropsEvents()
    {
        // Arrange - Small capacity with slow consumer
        await using var sink = new MockStorageSink { ProcessingDelay = TimeSpan.FromMilliseconds(100) };
        await using var pipeline = new EventPipeline(
            sink,
            capacity: 10,
            fullMode: BoundedChannelFullMode.DropOldest,
            enablePeriodicFlush: false);

        // Act - Publish more events than capacity
        // When publishing 100 events quickly, the channel (capacity=10) will drop the oldest
        for (int i = 0; i < 100; i++)
        {
            pipeline.TryPublish(CreateTradeEvent($"SYM{i}"));
        }

        // Wait for processing to complete - wait for a reasonable number of events
        // With capacity=10 and DropOldest, we expect roughly capacity + small epsilon
        var stopwatch = System.Diagnostics.Stopwatch.StartNew();
        var targetCount = 15; // capacity + small buffer for in-flight processing
        while (sink.ReceivedEvents.Count < targetCount && stopwatch.Elapsed < TimeSpan.FromSeconds(2))
        {
            await Task.Delay(1);
        }
        await pipeline.FlushAsync();

        // Assert - With DropOldest mode, all TryPublish calls succeed, so DroppedCount is 0
        // But sink should receive approximately capacity worth of events (latest ones)
        pipeline.DroppedCount.Should().Be(0, "DropOldest mode succeeds on TryPublish and doesn't increment DroppedCount");
        sink.ReceivedEvents.Count.Should().BeLessThan(100, "some events should have been dropped by the channel");

        // The events received should be the latest ones (high symbol numbers)
        // because oldest were dropped
        var receivedSymbols = sink.ReceivedEvents.Select(e => e.Symbol).ToList();
        var highSymbolCount = receivedSymbols.Count(s => int.Parse(s.Replace("SYM", "")) >= 90);
        highSymbolCount.Should().BeGreaterThan(0, "should have received some of the latest events (SYM90+)");
    }

    [Fact(Skip = "Timing-sensitive test that is flaky in CI - the consumer drains the channel too quickly")]
    public async Task TryPublish_WhenQueueFull_DropWriteMode_ReturnsFalse()
    {
        // Arrange - Small capacity with very slow consumer to guarantee queue stays full
        await using var sink = new MockStorageSink { ProcessingDelay = TimeSpan.FromMilliseconds(5000) };
        await using var pipeline = new EventPipeline(
            sink,
            capacity: 5,
            fullMode: BoundedChannelFullMode.DropWrite,
            enablePeriodicFlush: false);

        // Overfill the queue - publish many more than capacity
        // With a 5-second processing delay, the consumer won't drain any during this burst
        var dropCount = 0;
        for (int i = 0; i < 20; i++)
        {
            if (!pipeline.TryPublish(CreateTradeEvent("SPY")))
                dropCount++;
        }

        // Assert - With capacity=5 and 20 publishes against a 5s consumer,
        // at least some should have been dropped
        pipeline.DroppedCount.Should().BeGreaterThan(0,
            "DropWrite mode should reject events when the channel is full");
        await Task.CompletedTask;
    }

    #endregion

    #region Flush Tests

    [Fact]
    public async Task FlushAsync_FlushesUnderlyingSink()
    {
        // Arrange
        _pipeline.TryPublish(CreateTradeEvent("SPY"));
        await WaitForConsumption(expectedCount: 1);

        // Act
        await _pipeline.FlushAsync();

        // Assert
        _mockSink.FlushCount.Should().BeGreaterThanOrEqualTo(1);
    }

    [Fact]
    public async Task TimeSinceLastFlush_UpdatesAfterFlush()
    {
        // Arrange
        await Task.Delay(5);
        var timeBefore = _pipeline.TimeSinceLastFlush;

        // Act
        await _pipeline.FlushAsync();
        var timeAfter = _pipeline.TimeSinceLastFlush;

        // Assert
        timeAfter.Should().BeLessThan(timeBefore);
    }

    [Fact]
    public async Task PeriodicFlush_WhenEnabled_FlushesAutomatically()
    {
        // Arrange
        await using var sink = new MockStorageSink();
        await using var pipeline = new EventPipeline(
            sink,
            capacity: 1000,
            flushInterval: TimeSpan.FromMilliseconds(50),
            enablePeriodicFlush: true);

        pipeline.TryPublish(CreateTradeEvent("SPY"));

        // Act - Wait for periodic flush
        await Task.Delay(75);

        // Assert
        sink.FlushCount.Should().BeGreaterThanOrEqualTo(1);
    }

    #endregion

    #region Constructor Validation Tests

    [Theory]
    [InlineData(0)]
    [InlineData(-1)]
    [InlineData(-100)]
    public async Task Constructor_WithInvalidCapacity_ThrowsArgumentOutOfRangeException(int invalidCapacity)
    {
        // Arrange
        await using var sink = new MockStorageSink();

        // Act & Assert
        var exception = Assert.Throws<ArgumentOutOfRangeException>(
            () => new EventPipeline(sink, capacity: invalidCapacity));

        exception.ParamName.Should().Be("capacity");
        exception.ActualValue.Should().Be(invalidCapacity);
    }

    [Fact]
    public async Task Constructor_WithNullSink_ThrowsArgumentNullException()
    {
        // Act & Assert
        Assert.Throws<ArgumentNullException>(() => new EventPipeline(null!));
        await Task.CompletedTask;
    }

    #endregion

    #region Lifecycle Tests

    [Fact]
    public async Task Complete_SignalsNoMoreEvents()
    {
        // Arrange
        _pipeline.TryPublish(CreateTradeEvent("SPY"));

        // Act
        _pipeline.Complete();

        // Wait for pipeline to drain
        await Task.Delay(5);

        // Assert - Further publishes may fail
        // The channel is marked complete
        _mockSink.ReceivedEvents.Should().NotBeEmpty();
    }

    [Fact]
    public async Task DisposeAsync_FlushesFinalEvents()
    {
        // Arrange
        await using var sink = new MockStorageSink();
        var pipeline = new EventPipeline(sink, capacity: 1000, enablePeriodicFlush: false);

        pipeline.TryPublish(CreateTradeEvent("SPY"));
        pipeline.TryPublish(CreateTradeEvent("AAPL"));

        // Act
        await pipeline.DisposeAsync();

        // Assert - Sink should have received a final flush
        sink.FlushCount.Should().BeGreaterThanOrEqualTo(1);
    }

    [Fact]
    public async Task DisposeAsync_ProcessesPendingEvents()
    {
        // Arrange
        await using var sink = new MockStorageSink();
        var pipeline = new EventPipeline(sink, capacity: 1000, enablePeriodicFlush: false);

        for (int i = 0; i < 10; i++)
        {
            pipeline.TryPublish(CreateTradeEvent("SPY"));
        }

        // Give consumer time to start processing before disposal
        await Task.Delay(5);

        // Act
        await pipeline.DisposeAsync();

        // Assert - All events should be processed
        sink.ReceivedEvents.Should().HaveCount(10);
    }

    #endregion

    #region Shutdown Timeout Tests

    [Fact]
    public async Task DisposeAsync_WhenSinkFlushBlocks_CompletesWithinTimeout()
    {
        // Arrange - Use a sink whose flush blocks until its CancellationToken is cancelled.
        // Before the fix, the pipeline passed CancellationToken.None to the final flush,
        // meaning it would hang indefinitely. After the fix, a timeout token is used.
        // Use a short finalFlushTimeout (1s) so the test completes quickly.
        await using var sink = new CancellationAwareSlowFlushSink();
        var pipeline = new EventPipeline(sink, capacity: 100, enablePeriodicFlush: false,
            finalFlushTimeout: TimeSpan.FromSeconds(1));

        pipeline.TryPublish(CreateTradeEvent("SPY"));
        await Task.Delay(5); // Let consumer process the event

        // Act - Dispose should not hang; the final flush will be cancelled by finalFlushTimeout
        var disposeTask = pipeline.DisposeAsync().AsTask();
        var completed = await Task.WhenAny(disposeTask, Task.Delay(TimeSpan.FromSeconds(3)));

        // Assert - Disposal must complete (not hang indefinitely)
        completed.Should().Be(disposeTask,
            "DisposeAsync should complete within the timeout, not hang indefinitely");
    }

    [Fact]
    public async Task DisposeAsync_FinalFlush_ReceivesCancellableToken()
    {
        // Arrange - Sink that captures the CancellationToken passed to FlushAsync
        var sink = new TokenCapturingSink();
        var pipeline = new EventPipeline(sink, capacity: 100, enablePeriodicFlush: false);

        pipeline.TryPublish(CreateTradeEvent("SPY"));
        await Task.Delay(5); // Let consumer process

        // Act
        await pipeline.DisposeAsync();

        // Assert - The final flush should receive a cancellable token (not CancellationToken.None)
        sink.LastFlushToken.Should().NotBe(default(CancellationToken),
            "Final flush should receive a timeout-based CancellationToken, not CancellationToken.None");
        sink.LastFlushToken.CanBeCanceled.Should().BeTrue(
            "The CancellationToken passed to the final flush should be cancellable (tied to a timeout)");
    }

    #endregion

    #region Cancellation Tests

    [Fact(Skip = "Timing-sensitive test that is flaky in CI - the consumer drains the channel too quickly")]
    public async Task PublishAsync_WithCancellation_ThrowsWhenCancelled()
    {
        // Arrange - Use slow consumer and small capacity to force backpressure
        await using var sink = new MockStorageSink { ProcessingDelay = TimeSpan.FromMilliseconds(100) };
        // Use Wait mode with capacity=2 so we can fill it and block on the third write
        await using var pipeline = new EventPipeline(sink, capacity: 2, fullMode: BoundedChannelFullMode.Wait, enablePeriodicFlush: false);

        // Fill the channel completely (2 items)
        pipeline.TryPublish(CreateTradeEvent("SPY"));
        pipeline.TryPublish(CreateTradeEvent("MSFT"));

        // Wait a bit for consumer to start processing (but not finish due to delay)
        await Task.Delay(20);

        // Use a short cancellation timeout - the third publish should block since channel is full
        using var cts = new CancellationTokenSource(50);

        // Act & Assert - Third publish should block since channel is full and consumer is slow
        await Assert.ThrowsAnyAsync<OperationCanceledException>(
            async () => await pipeline.PublishAsync(CreateTradeEvent("AAPL"), cts.Token));
    }

    #endregion

    #region Error Handling Tests

    [Fact]
    public async Task Consumer_WhenSinkThrows_ContinuesProcessing()
    {
        // Arrange
        await using var sink = new MockStorageSink { ShouldThrowOnAppend = true, ThrowAfterCount = 5 };
        await using var pipeline = new EventPipeline(sink, capacity: 1000, enablePeriodicFlush: false);

        // Act - Publish events, some will cause exceptions
        for (int i = 0; i < 10; i++)
        {
            pipeline.TryPublish(CreateTradeEvent($"SYM{i}"));
        }

        await Task.Delay(10);

        // Assert - Pipeline should still be alive and processing
        // At least some events should have been processed before the throw
        sink.ReceivedEvents.Count.Should().BeGreaterThanOrEqualTo(5);
    }

    #endregion

    #region Throughput Tests

    [Fact]
    public async Task HighThroughput_ProcessesManyEventsQuickly()
    {
        // Arrange
        const int eventCount = 10000;
        await using var sink = new MockStorageSink();
        await using var pipeline = new EventPipeline(sink, capacity: 100000, enablePeriodicFlush: false);

        var sw = System.Diagnostics.Stopwatch.StartNew();

        // Act
        for (int i = 0; i < eventCount; i++)
        {
            pipeline.TryPublish(CreateTradeEvent("SPY"));
        }

        // Wait for all to be consumed
        while (pipeline.ConsumedCount < eventCount && sw.ElapsedMilliseconds < 5000)
        {
            await Task.Delay(1);
        }

        sw.Stop();

        // Assert
        pipeline.ConsumedCount.Should().Be(eventCount);
        sw.ElapsedMilliseconds.Should().BeLessThan(5000); // Should complete well within 5 seconds

        var eventsPerSecond = eventCount / (sw.ElapsedMilliseconds / 1000.0);
        eventsPerSecond.Should().BeGreaterThan(1000); // At least 1k events/sec
    }

    #endregion

    #region Helper Methods

    private static MarketEvent CreateTradeEvent(string symbol)
    {
        var trade = new Trade(
            Timestamp: DateTimeOffset.UtcNow,
            Symbol: symbol,
            Price: 100.50m,
            Size: 100,
            Aggressor: AggressorSide.Buy,
            SequenceNumber: 1,
            Venue: "NYSE");

        return MarketEvent.Trade(DateTimeOffset.UtcNow, symbol, trade);
    }

    private static MarketEvent CreateQuoteEvent(string symbol)
    {
        var quote = BboQuotePayload.FromUpdate(
            new MarketQuoteUpdate(
                Timestamp: DateTimeOffset.UtcNow,
                Symbol: symbol,
                BidPrice: 100.00m,
                BidSize: 100L,
                AskPrice: 100.10m,
                AskSize: 200L),
            seq: 1);

        return MarketEvent.BboQuote(DateTimeOffset.UtcNow, symbol, quote);
    }

    private async Task WaitForConsumption(int expectedCount, int timeoutMs = 2000)
    {
        var sw = System.Diagnostics.Stopwatch.StartNew();
        while (_mockSink.ReceivedEvents.Count < expectedCount && sw.ElapsedMilliseconds < timeoutMs)
        {
            await Task.Delay(1);
        }
    }

    #endregion
}

/// <summary>
/// Mock storage sink for testing the EventPipeline.
/// </summary>
internal sealed class MockStorageSink : IStorageSink
{
    private readonly List<MarketEvent> _receivedEvents = new();
    private readonly object _lock = new();
    private int _appendCount;

    public IReadOnlyList<MarketEvent> ReceivedEvents
    {
        get
        {
            lock (_lock)
            {
                return _receivedEvents.ToList();
            }
        }
    }

    public int FlushCount { get; private set; }

    public TimeSpan ProcessingDelay { get; set; } = TimeSpan.Zero;

    public bool ShouldThrowOnAppend { get; set; }

    public int ThrowAfterCount { get; set; } = int.MaxValue;

    public async ValueTask AppendAsync(MarketEvent evt, CancellationToken ct = default)
    {
        if (ProcessingDelay > TimeSpan.Zero)
        {
            await Task.Delay(ProcessingDelay, ct);
        }

        var count = Interlocked.Increment(ref _appendCount);

        if (ShouldThrowOnAppend && count > ThrowAfterCount)
        {
            throw new InvalidOperationException("Simulated sink failure");
        }

        lock (_lock)
        {
            _receivedEvents.Add(evt);
        }
    }

    public Task FlushAsync(CancellationToken ct = default)
    {
        FlushCount++;
        return Task.CompletedTask;
    }

    public ValueTask DisposeAsync()
    {
        return ValueTask.CompletedTask;
    }
}

/// <summary>
/// Mock sink whose FlushAsync blocks until the provided CancellationToken is cancelled.
/// Used to verify that the pipeline's final flush uses a cancellable token (not CancellationToken.None).
/// </summary>
internal sealed class CancellationAwareSlowFlushSink : IStorageSink
{
    public async ValueTask AppendAsync(MarketEvent evt, CancellationToken ct = default)
    {
        await Task.CompletedTask;
    }

    public async Task FlushAsync(CancellationToken ct = default)
    {
        // Block until cancelled - simulates a hung I/O operation that respects cancellation
        await Task.Delay(Timeout.InfiniteTimeSpan, ct);
    }

    public ValueTask DisposeAsync() => ValueTask.CompletedTask;
}

/// <summary>
/// Mock sink that captures the CancellationToken passed to FlushAsync
/// for assertion in tests.
/// </summary>
internal sealed class TokenCapturingSink : IStorageSink
{
    public CancellationToken LastFlushToken { get; private set; }

    public ValueTask AppendAsync(MarketEvent evt, CancellationToken ct = default) => ValueTask.CompletedTask;

    public Task FlushAsync(CancellationToken ct = default)
    {
        LastFlushToken = ct;
        return Task.CompletedTask;
    }

    public ValueTask DisposeAsync() => ValueTask.CompletedTask;
}
